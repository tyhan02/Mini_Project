{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55314ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file PosixPath('/opt/conda/lib/python3.8/site-packages/matplotlib/mpl-data/matplotlibrc'), line 758 ('font.family : NanumGothicCoding')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0de64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "datasets = pd.read_csv(path + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f90a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. x, y Data\n",
    "x = datasets[['id', 'bus_route_id', 'in_out', 'station_code', 'station_name',\n",
    "              'latitude', 'longitude', '6~7_ride', '7~8_ride', '8~9_ride',\n",
    "              '9~10_ride', '10~11_ride', '11~12_ride', '6~7_takeoff', '7~8_takeoff',\n",
    "              '8~9_takeoff', '9~10_takeoff','10~11_takeoff']].copy() #11~12 뺌\n",
    "\n",
    "\n",
    "x['takeon_avg_6~8'] = (x['6~7_ride'] + x['7~8_ride']) / 2\n",
    "x['takeon_avg_8~10'] = (x['8~9_ride'] + x['9~10_ride']) / 2\n",
    "x['takeon_avg_10~12'] = (x['10~11_ride'] + x['11~12_ride']) / 2\n",
    "\n",
    "x['takeon_avg_ride'] = (x['takeon_avg_6~8'] + x['takeon_avg_8~10'] + x['takeon_avg_10~12']) / 3\n",
    "\n",
    "\n",
    "x['takeoff_avg_6~8'] = (x['6~7_takeoff'] + x['7~8_takeoff']) / 2\n",
    "x['takeoff_avg_8~11'] = (x['8~9_takeoff'] + x['9~10_takeoff']+ x['10~11_takeoff']) / 3\n",
    "\n",
    "\n",
    "x['takeon_avg_takeoff'] = (x['takeoff_avg_6~8'] + x['takeoff_avg_8~11'] ) / 2\n",
    "\n",
    "x['date'] = pd.to_datetime(datasets['date']) \n",
    "y = datasets[['18~20_ride']]\n",
    "\n",
    "x['date'] = pd.to_datetime(x['date'])\n",
    "x['year'] = x['date'].dt.year\n",
    "x['month'] = x['date'].dt.month\n",
    "x['day'] = x['date'].dt.day\n",
    "x['weekday'] = x['date'].dt.weekday\n",
    "x = x.drop('date', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64728a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['in_out'] = x['in_out'].map({'시내': 0, '시외': 1})\n",
    "station_name_mapping = {name: i for i, name in enumerate(x['station_name'].unique())}\n",
    "x['station_name'] = x['station_name'].map(station_name_mapping)\n",
    "x_encoded = pd.get_dummies(x, columns=['station_name'])\n",
    "x_encoded = x_encoded.fillna(0)\n",
    "\n",
    "# x_encoded = x_encoded.replace([np.inf, -np.inf], np.nan)\n",
    "# mean_values = x_encoded.mean()\n",
    "# x_encoded = x_encoded.fillna(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8adf26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################기본 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35b5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(30) # weight 난수값 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab31e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(x.info())\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c99bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  bus_route_id  in_out  station_code  station_name  latitude  \\\n",
      "0            0       4270000       1           344             0  33.48990   \n",
      "1            1       4270000       1           357             1  33.48944   \n",
      "2            2       4270000       1           432             2  33.48181   \n",
      "3            3       4270000       0          1579             3  33.50577   \n",
      "4            4       4270000       0          1646             4  33.25579   \n",
      "...        ...           ...     ...           ...           ...       ...   \n",
      "415418  415418      32820000       0          1129            95  33.41437   \n",
      "415419  415419      32820000       0          1564            41  33.49946   \n",
      "415420  415420      32820000       0          2322           150  33.23100   \n",
      "415421  415421      32820000       0          3291            98  33.46483   \n",
      "415422  415422      32820000       0       6115100            46  33.24873   \n",
      "\n",
      "        longitude  6~7_ride  7~8_ride  8~9_ride  ...  takeon_avg_8~10  \\\n",
      "0       126.49373       0.0       1.0       2.0  ...              3.5   \n",
      "1       126.48508       1.0       4.0       4.0  ...              3.0   \n",
      "2       126.47352       1.0       1.0       0.0  ...              1.0   \n",
      "3       126.49252       0.0      17.0       6.0  ...             16.0   \n",
      "4       126.41260       0.0       0.0       0.0  ...              0.0   \n",
      "...           ...       ...       ...       ...  ...              ...   \n",
      "415418  126.26336       4.0       0.0       0.0  ...              0.0   \n",
      "415419  126.51479       4.0       0.0       0.0  ...              0.0   \n",
      "415420  126.26273       0.0       0.0       0.0  ...              0.0   \n",
      "415421  126.31870       1.0       0.0       0.0  ...              0.0   \n",
      "415422  126.50799       0.0       0.0       0.0  ...              0.0   \n",
      "\n",
      "        takeon_avg_10~12  takeon_avg_ride  takeoff_avg_6~8  takeoff_avg_8~11  \\\n",
      "0                    4.0         2.666667              0.0          0.000000   \n",
      "1                    5.5         3.666667              0.0          0.000000   \n",
      "2                    0.0         0.666667              0.0          0.000000   \n",
      "3                   15.0        13.166667              0.0          0.000000   \n",
      "4                    0.0         0.000000              0.0          0.333333   \n",
      "...                  ...              ...              ...               ...   \n",
      "415418               0.0         0.666667              0.0          0.000000   \n",
      "415419               0.0         0.666667              0.0          0.000000   \n",
      "415420               0.0         0.000000              0.5          0.000000   \n",
      "415421               0.0         0.166667              0.0          0.000000   \n",
      "415422               0.0         0.000000              0.0          1.333333   \n",
      "\n",
      "        takeon_avg_takeoff  year  month  day  weekday  \n",
      "0                 0.000000  2019      9    1        6  \n",
      "1                 0.000000  2019      9    1        6  \n",
      "2                 0.000000  2019      9    1        6  \n",
      "3                 0.000000  2019      9    1        6  \n",
      "4                 0.166667  2019      9    1        6  \n",
      "...                    ...   ...    ...  ...      ...  \n",
      "415418            0.000000  2019      9   30        0  \n",
      "415419            0.000000  2019      9   30        0  \n",
      "415420            0.250000  2019      9   30        0  \n",
      "415421            0.000000  2019      9   30        0  \n",
      "415422            0.666667  2019      9   30        0  \n",
      "\n",
      "[415423 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.15, train_size=0.85, random_state=80, shuffle=True\n",
    ") # 7:3에서 바꿈\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e60ff421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# param = {'n_estimators': 559, \n",
    "#              'depth': 9, \n",
    "#              'fold_permutation_block': 120, \n",
    "#              'learning_rate': 0.8767296308401672, \n",
    "#              'od_pval': 0.8042245591717342, \n",
    "#              'l2_leaf_reg': 1.9840469251833572, \n",
    "#              'random_state': 1510}\n",
    "\n",
    "# bagging = BaggingRegressor(\n",
    "#     base_estimator=DecisionTreeRegressor(),\n",
    "#     max_features=7,\n",
    "#     n_estimators=100,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=62\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0a01d42",
   "metadata": {},
   "outputs": [
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0c1a408ca846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Fitting model and predicting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "param = {'n_estimators': [559], \n",
    "         'depth': [9], \n",
    "         'fold_permutation_block': [120], \n",
    "         'learning_rate': [0.8767296308401672], \n",
    "         'od_pval': [0.8042245591717342], \n",
    "         'l2_leaf_reg': [1.9840469251833572], \n",
    "         'random_state': [1510]}\n",
    "\n",
    "cat = CatBoostRegressor()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "model = GridSearchCV(cat, param, cv=kfold, refit=True, n_jobs=-1)\n",
    "\n",
    "# Fitting model and predicting\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [3947],\n",
    "    'depth': [16],\n",
    "    'fold_permutation_block': [237],\n",
    "    'learning_rate': [0.8989964556692867],\n",
    "    'od_pval': [0.6429734179569129],\n",
    "    'l2_leaf_reg': [2.169943087966259],\n",
    "    'random_state': [1417]\n",
    "}\n",
    "\n",
    "bagging = BaggingRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(),\n",
    "    max_features=7,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=62\n",
    ")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = GridSearchCV(bagging, param, cv=kfold, refit=True, n_jobs=-1)\n",
    "\n",
    "depth = param['depth'][0]\n",
    "l2_leaf_reg = param['l2_leaf_reg'][0]\n",
    "border_count = param['fold_permutation_block'][0]\n",
    "\n",
    "print(f\"depth: {depth}\")\n",
    "print(f\"l2_leaf_reg: {l2_leaf_reg}\")\n",
    "print(f\"border_count: {border_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MinMaxScaler 0.711 0.709\n",
    "# scaler = MinMaxScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "# StandardScaler 0.715 0.7151\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# RobustScaler 0.709 0.709\n",
    "# scaler = RobustScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "# MaxAbsScaler 0.718 0.710 0.710\n",
    "# scaler = MaxAbsScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209721a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PowerTransformer 0.718 0.717 0.709 0.703\n",
    "# scaler = PowerTransformer()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "# # QuantileTransformer 0.714 0.711\n",
    "# scaler = QuantileTransformer(output_distribution='normal')\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "# # FunctionTransformer 0.718 0.702 0.707\n",
    "# scaler = FunctionTransformer(np.log1p)\n",
    "# x_train = scaler.transform(x_train)\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd662f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델구성\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68467f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from optuna import Trial, visualization\n",
    "# from optuna.samplers import TPESampler\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from catboost import CatBoostRegressor\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def objectiveCAT(trial: Trial, x_train, y_train, x_test):\n",
    "#     param = {'n_estimators': 559, \n",
    "#              'depth': 9, \n",
    "#              'fold_permutation_block': 120, \n",
    "#              'learning_rate': 0.8767296308401672, \n",
    "#              'od_pval': 0.8042245591717342, \n",
    "#              'l2_leaf_reg': 1.9840469251833572, \n",
    "#              'random_state': 1510}\n",
    "#     # 학습 모델 생성\n",
    "#     model = CatBoostRegressor(**param)\n",
    "#     CAT_model = model.fit(x_train, y_train, verbose=True) # 학습 진행\n",
    "#     # 모델 성능 확인\n",
    "#     score = r2_score(CAT_model.predict(x_test), y_test)\n",
    "#     return score\n",
    "\n",
    "# # MAE가 최소가 되는 방향으로 학습을 진행\n",
    "# # TPESampler : Sampler using TPE (Tree-structured Parzen Estimator) algorithm.\n",
    "# study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "\n",
    "# # n_trials 지정해주지 않으면, 무한 반복\n",
    "# study.optimize(lambda trial : objectiveCAT(trial, x, y, x_test), n_trials = 5)\n",
    "# print('Best trial : score {}, /nparams {}'.format(study.best_trial.value, \n",
    "#                                                   study.best_trial.params))\n",
    "\n",
    "# # 하이퍼파라미터별 중요도를 확인할 수 있는 그래프\n",
    "# print(optuna.visualization.plot_param_importances(study))\n",
    "# # 하이퍼파라미터 최적화 과정을 확인\n",
    "# optuna.visualization.plot_optimization_history(study)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 훈련 및 평가예측\n",
    "xgb = XGBRegressor()\n",
    "cat = CatBoostRegressor()\n",
    "lgbm = LGBMRegressor()\n",
    "\n",
    "regressors = [cat, xgb, lgbm]\n",
    "for model in regressors:\n",
    "    model.fit(x_train, y_train)\n",
    "    y_predict = model.predict(x_test)\n",
    "    score = r2_score(y_test, y_predict)\n",
    "    class_names = model.__class__.__name__\n",
    "    print('{0} 정확도 : {1: .4}'.format(class_names, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91d90f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MSE 계산\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "\n",
    "# MSE 값 출력\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_predict)\n",
    "plt.plot(y_test, y_predict, color='Red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 시각화 - 산점도 그래프 그리기\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test.values.ravel(), y_predict)\n",
    "plt.plot([min(y_test.values.ravel()), max(y_test.values.ravel())], [min(y_test.values.ravel()), max(y_test.values.ravel())], 'k--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a532c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4. 시각화 - 예측 오차의 분포 그래프 그리기\n",
    "error = y_predict - y_test.values.ravel()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(error, bins=30)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Prediction Error Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50354d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4. 시각화 - 상관계수 히트맵\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.set(rc = {'figure.figsize':(20, 15)})\n",
    "sns.heatmap(data=datasets.corr(),\n",
    "           square = True,\n",
    "            annot = True,\n",
    "            cbar = True,\n",
    "            cmap = 'coolwarm'\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837907f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
